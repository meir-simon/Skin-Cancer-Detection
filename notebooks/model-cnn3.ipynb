{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 63056,
     "databundleVersionId": 9094797,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30762,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os.path\nfrom PIL import Image\nfrom imblearn.under_sampling import RandomUnderSampler\nimport random",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.620459Z",
     "iopub.execute_input": "2024-08-26T20:26:31.620933Z",
     "iopub.status.idle": "2024-08-26T20:26:31.626590Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.620883Z",
     "shell.execute_reply": "2024-08-26T20:26:31.625518Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:06.640242Z",
     "start_time": "2024-08-26T21:25:03.678838Z"
    }
   },
   "id": "e7646087de8af974",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {},
   "id": "c8c6904179f2acc3"
  },
  {
   "cell_type": "code",
   "source": "from sklearn.model_selection import GroupShuffleSplit\nfrom sklearn.metrics import auc, roc_curve",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.628763Z",
     "iopub.execute_input": "2024-08-26T20:26:31.629134Z",
     "iopub.status.idle": "2024-08-26T20:26:31.637661Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.629092Z",
     "shell.execute_reply": "2024-08-26T20:26:31.636763Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:06.643087Z",
     "start_time": "2024-08-26T21:25:06.641345Z"
    }
   },
   "id": "ea82de2e5d188339",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Sampler\nfrom torch.optim import AdamW, Adam\nfrom torchvision.transforms import transforms, v2\nfrom torchvision.models import vgg16\nimport torchvision.models as models",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.639020Z",
     "iopub.execute_input": "2024-08-26T20:26:31.639417Z",
     "iopub.status.idle": "2024-08-26T20:26:31.648496Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.639373Z",
     "shell.execute_reply": "2024-08-26T20:26:31.647741Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:08.407762Z",
     "start_time": "2024-08-26T21:25:06.643851Z"
    }
   },
   "id": "c4916f72730df360",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": "# settings ",
   "metadata": {},
   "id": "4d0303bfbaed9cf3"
  },
  {
   "cell_type": "code",
   "source": "device = (\"cuda\" if torch.cuda.is_available() \n          else \"mps\" if torch.backends.mps.is_available() \n          else \"cpu\")\nprint(f\"device: {device}\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.649573Z",
     "iopub.execute_input": "2024-08-26T20:26:31.650014Z",
     "iopub.status.idle": "2024-08-26T20:26:31.659544Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.649968Z",
     "shell.execute_reply": "2024-08-26T20:26:31.658577Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:08.449664Z",
     "start_time": "2024-08-26T21:25:08.408369Z"
    }
   },
   "id": "6826ee201c1791d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "torch.manual_seed(1729)\ndevice_gen = torch.Generator(device)\ntorch.set_default_device(device)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.662113Z",
     "iopub.execute_input": "2024-08-26T20:26:31.662481Z",
     "iopub.status.idle": "2024-08-26T20:26:31.670962Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.662437Z",
     "shell.execute_reply": "2024-08-26T20:26:31.670056Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:08.456888Z",
     "start_time": "2024-08-26T21:25:08.451622Z"
    }
   },
   "id": "710c63dfefbfbd54",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "IN_KAGGLE = \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\nIN_COLAB = \"COLAB_GPU\" in os.environ\n\nif IN_COLAB:\n    from google.colab import userdata    \n    # only the first time\n    # os.environ[\"KAGGLE_KEY\"] = \"d0ebb5786a5a5439881827924cf0ccbd\"\n    # os.environ[\"KAGGLE_USERNAME\"] = \"yuda03979\"\n    # \n    # ! kaggle competitions download isic-2024-challenge\n    # ! unzip isic-2024-challenge.zip\n    IMG_DIR = \"/content/train-image/image\"\n    CSV_PATH = \"/content/train-metadata.csv\"\nelif IN_KAGGLE:\n    IMG_DIR = \"/kaggle/input/isic-2024-challenge/train-image/image\"\n    CSV_PATH = \"/kaggle/input/isic-2024-challenge/train-metadata.csv\"\nelse:\n    IMG_DIR = \"/Users/yuda/Desktop/data_bases/isic-2024-challenge/train-image/image\"\n    CSV_PATH = \"/Users/yuda/PycharmProjects/my_isic2024/isic-2024-challenge/train-metadata.csv\"",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.672197Z",
     "iopub.execute_input": "2024-08-26T20:26:31.672557Z",
     "iopub.status.idle": "2024-08-26T20:26:31.681769Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.672517Z",
     "shell.execute_reply": "2024-08-26T20:26:31.680853Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:08.459648Z",
     "start_time": "2024-08-26T21:25:08.457571Z"
    }
   },
   "id": "44ba331bbea0617c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "torch.manual_seed(1729)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.682872Z",
     "iopub.execute_input": "2024-08-26T20:26:31.683460Z",
     "iopub.status.idle": "2024-08-26T20:26:31.695157Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.683427Z",
     "shell.execute_reply": "2024-08-26T20:26:31.694114Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:08.464269Z",
     "start_time": "2024-08-26T21:25:08.460367Z"
    }
   },
   "id": "e3909ab642bad6d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14fac8af0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "def auc_80(y_pred, y):\n    fpr, tpr, thresholds = roc_curve(y, y_pred)\n    tpr_80 = [0.80 if i >= 0.80 else i for i in tpr]\n    return auc(fpr, tpr) - auc(fpr, tpr_80)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.696097Z",
     "iopub.execute_input": "2024-08-26T20:26:31.696458Z",
     "iopub.status.idle": "2024-08-26T20:26:31.702551Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.696417Z",
     "shell.execute_reply": "2024-08-26T20:26:31.701679Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:08.466649Z",
     "start_time": "2024-08-26T21:25:08.464923Z"
    }
   },
   "id": "51e78a033fbc3f61",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": "# data and constance",
   "metadata": {},
   "id": "e1c70d6e511d1d14"
  },
  {
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "IMG_SIZE = (224, 224)\n",
    "NUM_CLASSES = 1\n",
    "LR = 1e-4\n",
    "RANDOM_STATE = 40\n",
    "CLASS_1_AMOUNT_PER_BATCH = BATCH_SIZE // 2"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.703479Z",
     "iopub.execute_input": "2024-08-26T20:26:31.703830Z",
     "iopub.status.idle": "2024-08-26T20:26:31.715798Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.703786Z",
     "shell.execute_reply": "2024-08-26T20:26:31.714867Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:08.468977Z",
     "start_time": "2024-08-26T21:25:08.467450Z"
    }
   },
   "id": "237700c9f64b8abd",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": "ISIC_df = pd.read_csv(CSV_PATH)\nISIC_df = ISIC_df[[\"isic_id\", \"patient_id\", \"target\"]]\nISIC_df[\"img_path\"] = ISIC_df[\"isic_id\"].apply(lambda id: f\"{os.path.join(IMG_DIR, id)}.jpg\")\nISIC_df.drop([\"isic_id\"], axis=1, inplace=True)\nISIC_df",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.749909Z",
     "iopub.execute_input": "2024-08-26T20:26:31.750828Z",
     "iopub.status.idle": "2024-08-26T20:26:37.647103Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.750788Z",
     "shell.execute_reply": "2024-08-26T20:26:37.646114Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:10.808724Z",
     "start_time": "2024-08-26T21:25:08.469654Z"
    }
   },
   "id": "14dfe95d9c670025",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tw/t4_6l2cn5hz3hqm6tjzgwk5c0000gn/T/ipykernel_7213/2637853055.py:1: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ISIC_df = pd.read_csv(CSV_PATH)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        patient_id  target                                           img_path\n",
       "0       IP_1235828       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "1       IP_8170065       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "2       IP_6724798       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "3       IP_4111386       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "4       IP_8313778       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "...            ...     ...                                                ...\n",
       "401054  IP_1140263       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "401055  IP_5678181       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "401056  IP_0076153       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "401057  IP_5231513       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "401058  IP_6426047       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "\n",
       "[401059 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IP_1235828</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IP_8170065</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IP_6724798</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IP_4111386</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IP_8313778</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401054</th>\n",
       "      <td>IP_1140263</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401055</th>\n",
       "      <td>IP_5678181</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401056</th>\n",
       "      <td>IP_0076153</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401057</th>\n",
       "      <td>IP_5231513</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401058</th>\n",
       "      <td>IP_6426047</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401059 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "transform = v2.Compose([\n",
    "    v2.Resize(IMG_SIZE),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean = [0.6298, 0.5126, 0.4097], std = [0.1386, 0.1308, 0.1202]),\n",
    "])\n",
    "\n",
    "def augmentation_transform():\n",
    "    transform = [v2.RandomRotation(90, expand=False),\n",
    "                v2.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "                v2.CenterCrop(150),]\n",
    "    return random.choice(transform)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.648858Z",
     "iopub.execute_input": "2024-08-26T20:26:37.649200Z",
     "iopub.status.idle": "2024-08-26T20:26:37.656747Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.649164Z",
     "shell.execute_reply": "2024-08-26T20:26:37.655768Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:10.812520Z",
     "start_time": "2024-08-26T21:25:10.809473Z"
    }
   },
   "id": "f9a2754fb795c170",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": "# split according patients",
   "metadata": {},
   "id": "c157419b73ab712a"
  },
  {
   "cell_type": "code",
   "source": [
    "def initialize_dataset_10k_0(CSV_PATH):\n",
    "    '''\n",
    "    return two data frames with 10k target == 0, and all the target == 1.\n",
    "    train have 3/4 target == 1, and 1/4 in the val_df. each patients\n",
    "    :param CSV_PATH: path to the csv (train)\n",
    "    :return: (df, df); train and val\n",
    "    '''\n",
    "\n",
    "    # reading dataset\n",
    "    ISIC_df = pd.read_csv(CSV_PATH)\n",
    "    ISIC_df = ISIC_df[[\"isic_id\", \"patient_id\", \"target\"]]\n",
    "    ISIC_df[\"img_path\"] = ISIC_df[\"isic_id\"].apply(lambda id: f\"{os.path.join(IMG_DIR, id)}.jpg\")\n",
    "    ISIC_df.drop([\"isic_id\"], axis=1, inplace=True)\n",
    "\n",
    "    # splitting into target == 1 and target == 0\n",
    "    class_1_df = ISIC_df[ISIC_df[\"target\"] == 1].reset_index(drop=True)\n",
    "    class_0_df = ISIC_df[ISIC_df[\"target\"] == 0].reset_index(drop=True)\n",
    "\n",
    "    def split_according_patients(df, train_size, drop_patients=True):\n",
    "        X, y, groups = df, df[\"target\"], df[\"patient_id\"]\n",
    "\n",
    "        gss = GroupShuffleSplit(n_splits=1, train_size=train_size, random_state=RANDOM_STATE)\n",
    "        gss_gen = gss.split(X, y, groups)\n",
    "        train_index, val_index = next(gss_gen)\n",
    "        if drop_patients:\n",
    "            train_df = df.loc[train_index, [\"img_path\", \"target\"]].reset_index(drop=True)\n",
    "            val_df = df.loc[val_index, [\"img_path\", \"target\"]].reset_index(drop=True)\n",
    "        else:\n",
    "            train_df = df.loc[train_index, [\"img_path\", \"patient_id\", \"target\"]].reset_index(drop=True)\n",
    "            val_df = df.loc[val_index, [\"img_path\", \"patient_id\", \"target\"]].reset_index(drop=True)\n",
    "\n",
    "        print(f\"len train_df: {len(train_df)}\\nlen val_df: {len(val_df)}\")\n",
    "        return train_df, val_df\n",
    "\n",
    "    train_class_1_df, val_class_1_df = split_according_patients(class_1_df, 0.75, False)\n",
    "\n",
    "    def take_common_pationts(class_0_df, class_1_df):\n",
    "        '''\n",
    "        takes the patients that in class_0_df and class_1_df both.\n",
    "        :param class_0_df: target == 0\n",
    "        :param class_1_df: target == 1\n",
    "        :return: only the patients that in both df\n",
    "        '''\n",
    "        class_1_patients = class_1_df[\"patient_id\"].unique()\n",
    "        class_0_df = class_0_df[class_0_df[\"patient_id\"].isin(class_1_patients)]\n",
    "        return pd.concat((class_0_df, class_1_df), axis=0).reset_index(drop=True)\n",
    "\n",
    "    train_df = take_common_pationts(class_0_df, train_class_1_df)\n",
    "    val_df = take_common_pationts(class_0_df, val_class_1_df)\n",
    "    \n",
    "    return train_df, val_df\n",
    "\n",
    "\n",
    "\n",
    "def get_dataloader(df):\n",
    "    dataset = ISICDataset(train_df, transform, augmentation_transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    return dataloader \n",
    "\n",
    "\n",
    "\n",
    "def get_dataloader_with_undersampling(train_df, val_df, train_class_0_size=10000, val_class_0_size=10000):\n",
    "    train_class_1_size, val_class_1_size = len(train_df[train_df['target'] == 1]), len(val_df[val_df['target'] == 1])\n",
    "    train_df.sample(frac=1)\n",
    "    # under sampling\n",
    "    undersample = RandomUnderSampler(sampling_strategy={0: train_class_0_size, 1: train_class_1_size})\n",
    "    train_df, _ = undersample.fit_resample(train_df, train_df[\"target\"])\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    \n",
    "    undersample = RandomUnderSampler(sampling_strategy={0: val_class_0_size, 1: val_class_1_size})\n",
    "    val_df, _ = undersample.fit_resample(val_df, val_df[\"target\"])\n",
    "    val_df = val_df.reset_index(drop=True).iloc[::-1].reset_index(drop=True) # to make al the class_1 in the beginning\n",
    "    \n",
    "    class_1_train_df = train_df[train_df[\"target\"] == 1]\n",
    "    class_0_train_df = train_df[train_df[\"target\"] == 0]\n",
    "    \n",
    "    \n",
    "    train_ds = ISICDataset(train_df, transform=transform, augmentation_transform=augmentation_transform)\n",
    "    val_ds = ISICDataset(val_df, transform=transform)\n",
    "    \n",
    "    sampler = BalancedBatchSampler(class_0_train_df, class_1_train_df, batch_size=BATCH_SIZE, class_1_amount_per_batch=CLASS_1_AMOUNT_PER_BATCH)\n",
    "    \n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, generator=device_gen)\n",
    "    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, generator=device_gen)\n",
    "    \n",
    "    return train_dl, val_dl"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.658233Z",
     "iopub.execute_input": "2024-08-26T20:26:37.658811Z",
     "iopub.status.idle": "2024-08-26T20:26:37.679193Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.658765Z",
     "shell.execute_reply": "2024-08-26T20:26:37.678365Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:10.820014Z",
     "start_time": "2024-08-26T21:25:10.813311Z"
    }
   },
   "id": "cfccc140bfee9e1e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": "# ISIC_Dataset class",
   "metadata": {},
   "id": "3be3f552b219d7f4"
  },
  {
   "cell_type": "code",
   "source": "class ISICDataset(Dataset):\n    \n    def __init__(self, df, transform=None, augmentation_transform=None):\n        self.df = df\n        self.transform = transform\n        self.augmentation_transform = augmentation_transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.df.loc[idx, \"img_path\"]).convert(\"RGB\")\n        img = v2.Resize(IMG_SIZE)(img)\n        img = v2.ToDtype(torch.float32, scale=True)(img)\n        label = self.df.loc[idx, \"target\"]\n        if self.augmentation_transform:    \n            img = self.augmentation_transform()(img) if random.random() > 0.2 else img\n        img = self.transform(img)\n        # if random.random() > 0.98:\n        #     plt.imshow(img.permute(1, 2, 0))\n        #     plt.show()\n        return img, label\n\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.680249Z",
     "iopub.execute_input": "2024-08-26T20:26:37.680589Z",
     "iopub.status.idle": "2024-08-26T20:26:37.693447Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.680557Z",
     "shell.execute_reply": "2024-08-26T20:26:37.692619Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:10.823424Z",
     "start_time": "2024-08-26T21:25:10.820725Z"
    }
   },
   "id": "6c78f5c1786124dd",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "class BalancedBatchSampler(Sampler):\n\n    def __init__(self, class_0_df, class_1_df, batch_size, class_1_amount_per_batch=10):\n        self.class_0_df = class_0_df\n        self.class_1_df = class_1_df\n\n        self.batch_size = batch_size\n        self.class_1_amount_per_batch = class_1_amount_per_batch\n        self.num_batches = (len(self.class_0_df) + len(self.class_1_df)) // batch_size\n\n    def __iter__(self):\n        class_0_iter = iter(self.class_0_df.index)\n        class_1_iter = iter(self.class_1_df.index)\n        \n        for _ in range(self.num_batches):\n            batch = []\n            try:\n                for _ in range(self.class_1_amount_per_batch):\n                    batch.append(next(class_1_iter))\n            except:\n                class_1_iter = iter(self.class_1_df.index)\n                batch = []\n                for _ in range(self.class_1_amount_per_batch):\n                    batch.append(next(class_1_iter))\n            try:\n                for _ in range(self.batch_size - self.class_1_amount_per_batch):\n                    batch.append((next(class_0_iter)))\n            except:\n                class_0_iter = iter(self.class_0_df.index)\n                for _ in range(self.batch_size - self.class_1_amount_per_batch):\n                    batch.append(next(class_0_iter))\n            random.shuffle(batch)\n            for idx in batch:\n                yield idx\n\n    def __len__(self):\n        return self.num_batches\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.695760Z",
     "iopub.execute_input": "2024-08-26T20:26:37.696051Z",
     "iopub.status.idle": "2024-08-26T20:26:37.708764Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.696020Z",
     "shell.execute_reply": "2024-08-26T20:26:37.708002Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:10.829075Z",
     "start_time": "2024-08-26T21:25:10.825729Z"
    }
   },
   "id": "9768ee9b38740db3",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": "# model",
   "metadata": {},
   "id": "529705da4dca85bd"
  },
  {
   "cell_type": "code",
   "source": "def load_model(model_name=\"mobilenet_v3_small\", num_classes=2):\n\n    if model_name == \"mobilenet_v3_small\":\n        model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\n        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n    \n    elif model_name == \"efficientnet_v2_m\":\n        model = models.efficientnet_v2_m(weights=models.EfficientNet_V2_M_Weights.DEFAULT)\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n    \n    elif model_name == \"efficientnet_b0\":\n        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n    \n    elif model_name == \"vgg16\":\n        model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n    \n    elif model_name == \"resnet50\":\n        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n        model.fc = nn.Linear(model.fc.in_features, num_classes)\n    \n    elif model_name == \"resnet18\":\n        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n        model.fc = nn.Linear(model.fc.in_features, num_classes)\n    \n    elif model_name == \"vit_b_16\":\n        model = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n        in_features = model.heads.head.in_features\n        model.heads.head = nn.Linear(in_features, num_classes)\n    else:\n        raise ValueError(f\"Model {model_name} is not supported yet\")\n        \n#     print(model)\n    model = model.to(device)\n    optimizer = AdamW(model.parameters(), lr=LR)\n    criterion = nn.CrossEntropyLoss() if num_classes > 1 else nn.BCELoss()\n\n    return model, optimizer, criterion\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.709711Z",
     "iopub.execute_input": "2024-08-26T20:26:37.710029Z",
     "iopub.status.idle": "2024-08-26T20:26:37.722943Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.709996Z",
     "shell.execute_reply": "2024-08-26T20:26:37.722212Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:10.833379Z",
     "start_time": "2024-08-26T21:25:10.829887Z"
    }
   },
   "id": "ccba580879c42adc",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": "model, optimizer, criterion = load_model(num_classes=NUM_CLASSES)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.723949Z",
     "iopub.execute_input": "2024-08-26T20:26:37.724254Z",
     "iopub.status.idle": "2024-08-26T20:26:37.824412Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.724223Z",
     "shell.execute_reply": "2024-08-26T20:26:37.823643Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:20.666604Z",
     "start_time": "2024-08-26T21:25:10.834218Z"
    }
   },
   "id": "5fe80c1073873266",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /Users/yuda/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
      "100%|██████████| 9.83M/9.83M [00:08<00:00, 1.17MB/s]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": "# training func",
   "metadata": {},
   "id": "192c1018356be02a"
  },
  {
   "cell_type": "code",
   "source": "def train(dataloader, model, optimizer, criterion):\n    model.train()\n    total_loss = 0\n    sum_batches = 0\n    for batch, (imgs, labels) in enumerate(dataloader):\n        sum_batches += 1\n        imgs, labels = imgs.to(device), labels.to(device)\n        if NUM_CLASSES == 1:\n            labels = labels.unsqueeze(1).float()\n            pred_labels = model(imgs)\n            pred_labels = torch.sigmoid(pred_labels)\n        elif NUM_CLASSES == 2:\n            pred_labels = model(imgs)\n        else:\n            raise Exception(f\"define NUM_CLASSES\")\n        loss = criterion(pred_labels, labels)\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        total_loss += loss.item()\n        if batch % 10 == 0:\n            print(f\"{batch + 1} from {len(dataloader) * BATCH_SIZE}, loss: {loss}, auc: -\")\n    return total_loss / sum_batches\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.825957Z",
     "iopub.execute_input": "2024-08-26T20:26:37.826268Z",
     "iopub.status.idle": "2024-08-26T20:26:37.834469Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.826234Z",
     "shell.execute_reply": "2024-08-26T20:26:37.833470Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:20.670209Z",
     "start_time": "2024-08-26T21:25:20.667396Z"
    }
   },
   "id": "2d958b2eb5749d20",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "def test(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    pred_arr = [0, 1] # initialize for cases where only class_0 or only class_1 \n",
    "    labels_arr = [1, 0]\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (imgs, labels) in enumerate(dataloader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            if NUM_CLASSES == 1:\n",
    "                labels = labels.unsqueeze(1).float()\n",
    "    \n",
    "                pred_labels = model(imgs)\n",
    "                pred_labels = torch.sigmoid(pred_labels)\n",
    "                loss = criterion(pred_labels, labels)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                pred_arr = np.concatenate((pred_arr, pred_labels.cpu().flatten().detach().numpy()), axis=None)\n",
    "                labels_arr = np.concatenate((labels_arr, labels.cpu().flatten().detach().numpy()), axis=None)\n",
    "            elif NUM_CLASSES == 2:\n",
    "                # labels = labels.unsqueeze(1).float()\n",
    "                pred_labels = model(imgs)\n",
    "                # pred_labels = torch.sigmoid(pred_labels)\n",
    "                loss = criterion(pred_labels, labels)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                probabilities = nn.functional.softmax(pred_labels, dim=1)\n",
    "                # _, predicted_classes = torch.max(probabilities, dim=1)\n",
    "                \n",
    "                pred_arr = pred_arr + probabilities[:, 1].cpu().flatten().detach().numpy().tolist()\n",
    "                labels_arr = labels_arr + labels.detach().flatten().cpu().numpy().tolist()\n",
    "            else:\n",
    "                raise Exception(f\"define NUM_CLASSES\")\n",
    "            \n",
    "            if batch % 5 == 0:\n",
    "                print(f\"{batch + 1} from {len(dataloader)}, loss: {loss}, auc: {auc_80(pred_arr, labels_arr)}\")\n",
    "    return total_loss / len(dataloader), auc_80(pred_arr, labels_arr)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.835599Z",
     "iopub.execute_input": "2024-08-26T20:26:37.835943Z",
     "iopub.status.idle": "2024-08-26T20:26:37.849039Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.835911Z",
     "shell.execute_reply": "2024-08-26T20:26:37.848200Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:20.674278Z",
     "start_time": "2024-08-26T21:25:20.670894Z"
    }
   },
   "id": "507e17d1e98eab3e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": "## initialize the data",
   "metadata": {},
   "id": "ce719341aed6f0c9"
  },
  {
   "cell_type": "code",
   "source": "train_df, val_df = initialize_dataset_10k_0(CSV_PATH)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.850174Z",
     "iopub.execute_input": "2024-08-26T20:26:37.850628Z",
     "iopub.status.idle": "2024-08-26T20:26:43.930149Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.850585Z",
     "shell.execute_reply": "2024-08-26T20:26:43.929129Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:23.248483Z",
     "start_time": "2024-08-26T21:25:20.675059Z"
    }
   },
   "id": "6e2a7f7a34f6c5fb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tw/t4_6l2cn5hz3hqm6tjzgwk5c0000gn/T/ipykernel_7213/834590914.py:10: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ISIC_df = pd.read_csv(CSV_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train_df: 306\n",
      "len val_df: 87\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": "# start runing",
   "metadata": {},
   "id": "13b7cc90a58e2470"
  },
  {
   "cell_type": "code",
   "source": "train_loss_arr = []\ntest_loss_arr = []\ntest_auc_arr = []",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:43.931536Z",
     "iopub.execute_input": "2024-08-26T20:26:43.931933Z",
     "iopub.status.idle": "2024-08-26T20:26:43.936808Z",
     "shell.execute_reply.started": "2024-08-26T20:26:43.931878Z",
     "shell.execute_reply": "2024-08-26T20:26:43.935740Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:23.251152Z",
     "start_time": "2024-08-26T21:25:23.249351Z"
    }
   },
   "id": "8ac83199f38e53be",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "gap = \"------------------------------\"\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_dataloader, val_dataloader = get_dataloader_with_undersampling(train_df, val_df, 2000, 2000)\n",
    "\n",
    "\n",
    "    print(f\"{gap}\\nepoch: {epoch + 1}\\n{gap}\")\n",
    "    \n",
    "    print(\"train:\")\n",
    "    train_loss_arr.append(train(train_dataloader, model, optimizer, criterion))\n",
    "    print(\"test:\")\n",
    "    loss, auc_ = test(val_dataloader, model, criterion)\n",
    "    \n",
    "    test_loss_arr.append(loss)\n",
    "    test_auc_arr.append(auc_)\n",
    "    print(f\"train_loss_arr: {train_loss_arr[-1]} ; test_loss_arr: {test_loss_arr[-1]} ; test_auc_arr: {test_auc_arr[-1]} ;\")\n",
    "    # torch.save(model.state_dict(), f\"model_{epoch + 1}.pth\")\n",
    "    # print(f\"Saved PyTorch Model State to model_{epoch + 1}.pth\")\n",
    "print(\"done!\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:43.938221Z",
     "iopub.execute_input": "2024-08-26T20:26:43.938718Z",
     "iopub.status.idle": "2024-08-26T20:30:31.561107Z",
     "shell.execute_reply.started": "2024-08-26T20:26:43.938669Z",
     "shell.execute_reply": "2024-08-26T20:30:31.560017Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T21:25:32.186706Z",
     "start_time": "2024-08-26T21:25:23.252008Z"
    }
   },
   "id": "98e8fe43dcc2fd62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "epoch: 1\n",
      "------------------------------\n",
      "train:\n",
      "1 from 96, loss: 0.7332229614257812, auc: -\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgap\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mepoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mgap\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m train_loss_arr\u001B[38;5;241m.\u001B[39mappend(train(train_dataloader, model, optimizer, criterion))\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     12\u001B[0m loss, auc_ \u001B[38;5;241m=\u001B[39m test(val_dataloader, model, criterion)\n",
      "Cell \u001B[0;32mIn[17], line 5\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(dataloader, model, optimizer, criterion)\u001B[0m\n\u001B[1;32m      3\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      4\u001B[0m sum_batches \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch, (imgs, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader):\n\u001B[1;32m      6\u001B[0m     sum_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m      7\u001B[0m     imgs, labels \u001B[38;5;241m=\u001B[39m imgs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[1;32m    707\u001B[0m ):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[0;32mIn[13], line 17\u001B[0m, in \u001B[0;36mISICDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     15\u001B[0m label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf\u001B[38;5;241m.\u001B[39mloc[idx, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maugmentation_transform:    \n\u001B[0;32m---> 17\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maugmentation_transform()(img) \u001B[38;5;28;01mif\u001B[39;00m random\u001B[38;5;241m.\u001B[39mrandom() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0.2\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m img\n\u001B[1;32m     18\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(img)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# if random.random() > 0.98:\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m#     plt.imshow(img.permute(1, 2, 0))\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m#     plt.show()\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1750\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchvision/transforms/v2/_transform.py:167\u001B[0m, in \u001B[0;36m_RandomApplyTransform.forward\u001B[0;34m(self, *inputs)\u001B[0m\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inputs\n\u001B[1;32m    166\u001B[0m needs_transform_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_needs_transform_list(flat_inputs)\n\u001B[0;32m--> 167\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_params(\n\u001B[1;32m    168\u001B[0m     [inpt \u001B[38;5;28;01mfor\u001B[39;00m (inpt, needs_transform) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(flat_inputs, needs_transform_list) \u001B[38;5;28;01mif\u001B[39;00m needs_transform]\n\u001B[1;32m    169\u001B[0m )\n\u001B[1;32m    171\u001B[0m flat_outputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    172\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform(inpt, params) \u001B[38;5;28;01mif\u001B[39;00m needs_transform \u001B[38;5;28;01melse\u001B[39;00m inpt\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (inpt, needs_transform) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(flat_inputs, needs_transform_list)\n\u001B[1;32m    174\u001B[0m ]\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tree_unflatten(flat_outputs, spec)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchvision/transforms/v2/_geometry.py:982\u001B[0m, in \u001B[0;36mRandomPerspective._get_params\u001B[0;34m(self, flat_inputs)\u001B[0m\n\u001B[1;32m    980\u001B[0m startpoints \u001B[38;5;241m=\u001B[39m [[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m], [width \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m], [width \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, height \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m], [\u001B[38;5;241m0\u001B[39m, height \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m]]\n\u001B[1;32m    981\u001B[0m endpoints \u001B[38;5;241m=\u001B[39m [topleft, topright, botright, botleft]\n\u001B[0;32m--> 982\u001B[0m perspective_coeffs \u001B[38;5;241m=\u001B[39m _get_perspective_coeffs(startpoints, endpoints)\n\u001B[1;32m    983\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mdict\u001B[39m(coefficients\u001B[38;5;241m=\u001B[39mperspective_coeffs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchvision/transforms/functional.py:693\u001B[0m, in \u001B[0;36m_get_perspective_coeffs\u001B[0;34m(startpoints, endpoints)\u001B[0m\n\u001B[1;32m    689\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(startpoints) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m4\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(endpoints) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m4\u001B[39m:\n\u001B[1;32m    690\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    691\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease provide exactly four corners, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(startpoints)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m startpoints and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(endpoints)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m endpoints.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    692\u001B[0m     )\n\u001B[0;32m--> 693\u001B[0m a_matrix \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(startpoints), \u001B[38;5;241m8\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[1;32m    695\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (p1, p2) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(endpoints, startpoints)):\n\u001B[1;32m    696\u001B[0m     a_matrix[\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m i, :] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([p1[\u001B[38;5;241m0\u001B[39m], p1[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m-\u001B[39mp2[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m p1[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m-\u001B[39mp2[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m p1[\u001B[38;5;241m1\u001B[39m]])\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/_device.py:79\u001B[0m, in \u001B[0;36mDeviceContext.__torch_function__\u001B[0;34m(self, func, types, args, kwargs)\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m func \u001B[38;5;129;01min\u001B[39;00m _device_constructors() \u001B[38;5;129;01mand\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\n\u001B[0;32m---> 79\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[0;31mTypeError\u001B[0m: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead."
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": "# torch.save(model.state_dict(), \"model_.pth\")\n# print(\"Saved PyTorch Model State to model.pth\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:30:31.562687Z",
     "iopub.execute_input": "2024-08-26T20:30:31.563331Z",
     "iopub.status.idle": "2024-08-26T20:30:31.567115Z",
     "shell.execute_reply.started": "2024-08-26T20:30:31.563267Z",
     "shell.execute_reply": "2024-08-26T20:30:31.566297Z"
    },
    "trusted": true
   },
   "id": "67fc75e04c274738",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "print(f\"train_loss_arr: {train_loss_arr} ;\\n test_loss_arr: {test_loss_arr} ;\\n test_auc_arr: {test_auc_arr} ;\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:30:31.570135Z",
     "iopub.execute_input": "2024-08-26T20:30:31.570515Z",
     "iopub.status.idle": "2024-08-26T20:30:31.586055Z",
     "shell.execute_reply.started": "2024-08-26T20:30:31.570475Z",
     "shell.execute_reply": "2024-08-26T20:30:31.585259Z"
    },
    "trusted": true
   },
   "id": "2e5954b197e75f6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "pd.DataFrame({\"train_loss_arr\":train_loss_arr, \"test_loss_arr\":test_loss_arr, \"test_auc_arr\":test_auc_arr})\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:30:31.587036Z",
     "iopub.execute_input": "2024-08-26T20:30:31.587347Z",
     "iopub.status.idle": "2024-08-26T20:30:31.605554Z",
     "shell.execute_reply.started": "2024-08-26T20:30:31.587294Z",
     "shell.execute_reply": "2024-08-26T20:30:31.604456Z"
    },
    "trusted": true
   },
   "id": "d14072302e268df1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# to play with: class_1_amount_per_batch\n#",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:30:31.606603Z",
     "iopub.execute_input": "2024-08-26T20:30:31.606910Z",
     "iopub.status.idle": "2024-08-26T20:30:31.615682Z",
     "shell.execute_reply.started": "2024-08-26T20:30:31.606867Z",
     "shell.execute_reply": "2024-08-26T20:30:31.614814Z"
    },
    "trusted": true
   },
   "id": "4d96aa1e03f08f63",
   "outputs": [],
   "execution_count": null
  }
 ]
}
