{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 63056,
     "databundleVersionId": 9094797,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30762,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "from PIL import Image\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import random\n",
    "import math"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.620459Z",
     "iopub.execute_input": "2024-08-26T20:26:31.620933Z",
     "iopub.status.idle": "2024-08-26T20:26:31.626590Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.620883Z",
     "shell.execute_reply": "2024-08-26T20:26:31.625518Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T14:34:03.756682Z",
     "start_time": "2024-08-27T14:34:03.754504Z"
    }
   },
   "id": "e7646087de8af974",
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {},
   "id": "c8c6904179f2acc3"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold\n",
    "from sklearn.metrics import auc, roc_curve, confusion_matrix, average_precision_score, precision_recall_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.628763Z",
     "iopub.execute_input": "2024-08-26T20:26:31.629134Z",
     "iopub.status.idle": "2024-08-26T20:26:31.637661Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.629092Z",
     "shell.execute_reply": "2024-08-26T20:26:31.636763Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T14:34:03.852144Z",
     "start_time": "2024-08-27T14:34:03.850491Z"
    }
   },
   "id": "ea82de2e5d188339",
   "outputs": [],
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch.optim import AdamW, Adam\n",
    "from torchvision.transforms import transforms, v2\n",
    "from torchvision.models import vgg16\n",
    "import torchvision.models as models"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.639020Z",
     "iopub.execute_input": "2024-08-26T20:26:31.639417Z",
     "iopub.status.idle": "2024-08-26T20:26:31.648496Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.639373Z",
     "shell.execute_reply": "2024-08-26T20:26:31.647741Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T14:34:03.864386Z",
     "start_time": "2024-08-27T14:34:03.862423Z"
    }
   },
   "id": "c4916f72730df360",
   "outputs": [],
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "source": "# settings ",
   "metadata": {},
   "id": "4d0303bfbaed9cf3"
  },
  {
   "cell_type": "code",
   "source": "device = (\"cuda\" if torch.cuda.is_available() \n          else \"mps\" if torch.backends.mps.is_available() \n          else \"cpu\")\nprint(f\"device: {device}\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.649573Z",
     "iopub.execute_input": "2024-08-26T20:26:31.650014Z",
     "iopub.status.idle": "2024-08-26T20:26:31.659544Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.649968Z",
     "shell.execute_reply": "2024-08-26T20:26:31.658577Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T14:34:03.871107Z",
     "start_time": "2024-08-27T14:34:03.869172Z"
    }
   },
   "id": "6826ee201c1791d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "source": "torch.manual_seed(1729)\ndevice_gen = torch.Generator(device)\ntorch.set_default_device(device)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.662113Z",
     "iopub.execute_input": "2024-08-26T20:26:31.662481Z",
     "iopub.status.idle": "2024-08-26T20:26:31.670962Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.662437Z",
     "shell.execute_reply": "2024-08-26T20:26:31.670056Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T14:34:03.875130Z",
     "start_time": "2024-08-27T14:34:03.872695Z"
    }
   },
   "id": "710c63dfefbfbd54",
   "outputs": [],
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "source": [
    "IN_KAGGLE = \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
    "IN_COLAB = \"COLAB_GPU\" in os.environ\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata    \n",
    "    # only the first time\n",
    "    # os.environ[\"KAGGLE_KEY\"] = \"d0ebb5786a5a5439881827924cf0ccbd\"\n",
    "    # os.environ[\"KAGGLE_USERNAME\"] = \"yuda03979\"\n",
    "    # \n",
    "    # ! kaggle competitions download isic-2024-challenge\n",
    "    # ! unzip isic-2024-challenge.zip\n",
    "    IMG_DIR = \"/content/train-image/image\"\n",
    "    CSV_PATH = \"/content/train-metadata.csv\"\n",
    "elif IN_KAGGLE:\n",
    "    IMG_DIR = \"/kaggle/input/isic-2024-challenge/train-image/image\"\n",
    "    CSV_PATH = \"/kaggle/input/isic-2024-challenge/train-metadata.csv\"\n",
    "    IRRELEVANT_IMGS_PATH = \"/kaggle/input/irrelevant-images/top_10000_img_names.csv\" # get from benzi\n",
    "else:\n",
    "    IMG_DIR = \"/Users/yuda/Desktop/data_bases/isic-2024-challenge/train-image/image\"\n",
    "    CSV_PATH = \"/Users/yuda/PycharmProjects/my_isic2024/isic-2024-challenge/train-metadata.csv\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.672197Z",
     "iopub.execute_input": "2024-08-26T20:26:31.672557Z",
     "iopub.status.idle": "2024-08-26T20:26:31.681769Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.672517Z",
     "shell.execute_reply": "2024-08-26T20:26:31.680853Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T14:34:03.907326Z",
     "start_time": "2024-08-27T14:34:03.905121Z"
    }
   },
   "id": "44ba331bbea0617c",
   "outputs": [],
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "source": "torch.manual_seed(1729)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.682872Z",
     "iopub.execute_input": "2024-08-26T20:26:31.683460Z",
     "iopub.status.idle": "2024-08-26T20:26:31.695157Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.683427Z",
     "shell.execute_reply": "2024-08-26T20:26:31.694114Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T14:34:03.921040Z",
     "start_time": "2024-08-27T14:34:03.918150Z"
    }
   },
   "id": "e3909ab642bad6d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16a0da770>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "source": [
    "def roc_auc_80(y_pred, y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_pred)\n",
    "    tpr_80 = [0.80 if i >= 0.80 else i for i in tpr]\n",
    "    return auc(fpr, tpr) - auc(fpr, tpr_80)\n",
    "\n",
    "def pr_rc_auc(y_pred, y):\n",
    "    precision, recall, thresholds = precision_recall_curve(y, y_pred)\n",
    "    return auc(recall, precision)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.696097Z",
     "iopub.execute_input": "2024-08-26T20:26:31.696458Z",
     "iopub.status.idle": "2024-08-26T20:26:31.702551Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.696417Z",
     "shell.execute_reply": "2024-08-26T20:26:31.701679Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T14:34:03.923718Z",
     "start_time": "2024-08-27T14:34:03.921931Z"
    }
   },
   "id": "51e78a033fbc3f61",
   "outputs": [],
   "execution_count": 115
  },
  {
   "cell_type": "markdown",
   "source": "# data and constance",
   "metadata": {},
   "id": "e1c70d6e511d1d14"
  },
  {
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "IMG_SIZE = (150, 150)\n",
    "NUM_CLASSES = 2\n",
    "LR = 3e-5\n",
    "RANDOM_STATE = 42\n",
    "CLASS_1_AMOUNT_PER_BATCH = BATCH_SIZE // 2\n",
    "TRAIN_CLASS_1_SIZE, VAL_CLASS_1_SIZE, TRAIN_CLASS_0_SIZE, VAL_CLASS_0_SIZE = None, None, 5000, 5000\n",
    "N_SPLITS = 10\n",
    "NAMES_SAVED_MODELS = f\"04_09_2024_{IMG_SIZE[0]}_{NUM_CLASSES}\"\n",
    "T_0 = NUM_EPOCHS * ((TRAIN_CLASS_0_SIZE + 300) // BATCH_SIZE)\n",
    "MORE_IMGS = False"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.703479Z",
     "iopub.execute_input": "2024-08-26T20:26:31.703830Z",
     "iopub.status.idle": "2024-08-26T20:26:31.715798Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.703786Z",
     "shell.execute_reply": "2024-08-26T20:26:31.714867Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T14:34:03.936675Z",
     "start_time": "2024-08-27T14:34:03.934732Z"
    }
   },
   "id": "237700c9f64b8abd",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "MODELS_NAMES = [\n",
    "#     \"mobilenet_v3_small\",\n",
    "#     \"efficientnet_v2_m\",\n",
    "#     \"efficientnet_b0\",\n",
    "#     \"vgg16\",\n",
    "    \"resnet50\",\n",
    "#     \"resnet18\",\n",
    "#     \"vit_b_16\" # support only image_size of (224, 224)\n",
    "]"
   ],
   "id": "9724c26ba94119d5"
  },
  {
   "cell_type": "code",
   "source": [
    "ISIC_df = pd.read_csv(CSV_PATH)\n",
    "ISIC_df = ISIC_df[[\"isic_id\", \"patient_id\", \"target\"]]\n",
    "ISIC_df[\"img_path\"] = ISIC_df[\"isic_id\"].apply(lambda id: f\"{os.path.join(IMG_DIR, id)}.jpg\")\n",
    "irrelevant_imgs_df = pd.read_csv(IRRELEVANT_IMGS_PATH)\n",
    "ISIC_Ddf = ISIC_df[~ISIC_df[\"isic_id\"].isin(irrelevant_imgs_df[\"img_name\"])]\n",
    "ISIC_df.drop([\"isic_id\"], axis=1, inplace=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:31.749909Z",
     "iopub.execute_input": "2024-08-26T20:26:31.750828Z",
     "iopub.status.idle": "2024-08-26T20:26:37.647103Z",
     "shell.execute_reply.started": "2024-08-26T20:26:31.750788Z",
     "shell.execute_reply": "2024-08-26T20:26:37.646114Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T14:34:06.672515Z",
     "start_time": "2024-08-27T14:34:03.953541Z"
    }
   },
   "id": "14dfe95d9c670025",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tw/t4_6l2cn5hz3hqm6tjzgwk5c0000gn/T/ipykernel_45179/2637853055.py:1: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ISIC_df = pd.read_csv(CSV_PATH)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        patient_id  target                                           img_path\n",
       "0       IP_1235828       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "1       IP_8170065       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "2       IP_6724798       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "3       IP_4111386       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "4       IP_8313778       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "...            ...     ...                                                ...\n",
       "401054  IP_1140263       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "401055  IP_5678181       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "401056  IP_0076153       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "401057  IP_5231513       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "401058  IP_6426047       0  /Users/yuda/Desktop/data_bases/isic-2024-chall...\n",
       "\n",
       "[401059 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IP_1235828</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IP_8170065</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IP_6724798</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IP_4111386</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IP_8313778</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401054</th>\n",
       "      <td>IP_1140263</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401055</th>\n",
       "      <td>IP_5678181</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401056</th>\n",
       "      <td>IP_0076153</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401057</th>\n",
       "      <td>IP_5231513</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401058</th>\n",
       "      <td>IP_6426047</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/yuda/Desktop/data_bases/isic-2024-chall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401059 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "kfold",
   "id": "30ef6478a201fdf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:34:06.755902Z",
     "start_time": "2024-08-27T14:34:06.676692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "groups = ISIC_df['patient_id']\n",
    "k_fold = GroupKFold(n_splits=N_SPLITS)\n",
    "df_arr = []\n",
    "for (train_idx, val_idx) in k_fold.split(ISIC_df, groups=groups):\n",
    "    df_arr.append([train_idx, val_idx])\n"
   ],
   "id": "c37fdad392b63e5f",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[119], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m groups \u001B[38;5;241m=\u001B[39m ISIC_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpatient_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m----> 2\u001B[0m k_fold \u001B[38;5;241m=\u001B[39m GroupKFold(n_splits\u001B[38;5;241m=\u001B[39mK)\n\u001B[1;32m      3\u001B[0m df_arr \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (train_df, val_df) \u001B[38;5;129;01min\u001B[39;00m k_fold\u001B[38;5;241m.\u001B[39msplit(ISIC_df, groups\u001B[38;5;241m=\u001B[39mgroups):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:559\u001B[0m, in \u001B[0;36mGroupKFold.__init__\u001B[0;34m(self, n_splits)\u001B[0m\n\u001B[1;32m    558\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m--> 559\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(n_splits, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:321\u001B[0m, in \u001B[0;36m_BaseKFold.__init__\u001B[0;34m(self, n_splits, shuffle, random_state)\u001B[0m\n\u001B[1;32m    318\u001B[0m n_splits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(n_splits)\n\u001B[1;32m    320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_splits \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 321\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    322\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mk-fold cross-validation requires at least one\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    323\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m train/test split by setting n_splits=2 or more,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    324\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m got n_splits=\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits)\n\u001B[1;32m    325\u001B[0m     )\n\u001B[1;32m    327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(shuffle, \u001B[38;5;28mbool\u001B[39m):\n\u001B[1;32m    328\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshuffle must be True or False; got \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shuffle))\n",
      "\u001B[0;31mValueError\u001B[0m: k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=1."
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "cell_type": "markdown",
   "source": "# ISIC_Dataset class",
   "metadata": {},
   "id": "3be3f552b219d7f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def get_dataloader(df):\n",
    "    dataset = ISICDataset(train_df, transform, augmentation_transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def get_dataloader_with_undersampling(train_df, val_df, train_class_0_size=10000, val_class_0_size=10000):\n",
    "    print(type(train_df))\n",
    "    train_class_1_size, val_class_1_size = len(train_df[train_df['target'] == 1]), len(val_df[val_df['target'] == 1])\n",
    "    train_df.sample(frac=1)\n",
    "    # under sampling\n",
    "    undersample = RandomUnderSampler(sampling_strategy={0: train_class_0_size, 1: train_class_1_size})\n",
    "    train_df, _ = undersample.fit_resample(train_df, train_df[\"target\"])\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "    undersample = RandomUnderSampler(sampling_strategy={0: val_class_0_size, 1: val_class_1_size})\n",
    "    val_df, _ = undersample.fit_resample(val_df, val_df[\"target\"])\n",
    "    val_df = val_df.reset_index(drop=True).iloc[::-1].reset_index(drop=True)  # to make al the class_1 in the beginning\n",
    "\n",
    "    class_1_train_df = train_df[train_df[\"target\"] == 1]\n",
    "    class_0_train_df = train_df[train_df[\"target\"] == 0]\n",
    "\n",
    "    train_ds = ISICDataset(train_df, transform=transform, augmentation_transform=augmentation_transform)\n",
    "    val_ds = ISICDataset(val_df, transform=transform)\n",
    "\n",
    "    sampler = BalancedBatchSampler(class_0_train_df, class_1_train_df, batch_size=BATCH_SIZE,\n",
    "                                   class_1_amount_per_batch=CLASS_1_AMOUNT_PER_BATCH)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, generator=device_gen)\n",
    "    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, generator=device_gen)\n",
    "\n",
    "    return train_dl, val_dl"
   ],
   "id": "6d89711dc03324a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def add_random_noise(image, noise_level=20):\n",
    "    \"\"\"\n",
    "    Adds random noise to an image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image (PIL.Image.Image): The input image to which noise will be added.\n",
    "    - noise_level (int): The maximum absolute value of the noise to add to each pixel channel.\n",
    "    \n",
    "    Returns:\n",
    "    - PIL.Image.Image: The image with added random noise.\n",
    "    \"\"\"\n",
    "    image_array = np.array(image)\n",
    "    noise = np.random.randint(-noise_level, noise_level + 1, image_array.shape)\n",
    "    noisy_image_array = image_array + noise\n",
    "    noisy_image = Image.fromarray(noisy_image_array.astype(np.uint8))\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.Resize(IMG_SIZE),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean = [0.6298, 0.5126, 0.4097], std = [0.1386, 0.1308, 0.1202]),\n",
    "])\n",
    "\n",
    "def augmentation_transform():\n",
    "    transform = [\n",
    "        v2.RandomRotation(degrees=(-180, 180), expand=False),\n",
    "        v2.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        v2.RandomHorizontalFlip(0.5),\n",
    "        v2.RandomVerticalFlip(0.5),\n",
    "        v2.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.2)),\n",
    "        v2.RandomGrayscale(p=0.1),\n",
    "        v2.Lambda(lambda img: add_random_noise(img)),\n",
    "        v2.Lambda(lambda img: img),\n",
    "        v2.Lambda(lambda img: img),\n",
    "        v2.Lambda(lambda img: img),\n",
    "        \n",
    "#         v2.Lambda(lambda img: add_gaussian_noise(img, mean=0, std=0.1)),  # Custom function to add Gaussian noise\n",
    "#         v2.Lambda(lambda img: elastic_transform(img, alpha=34, sigma=4)),  # Custom function to apply elastic transformations]\n",
    "    ]\n",
    "    return random.choice(transform)\n",
    "\n",
    "val_transform = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(0.23),\n",
    "    v2.RandomVerticalFlip(0.23),\n",
    "])"
   ],
   "id": "363505ad4e1f867d"
  },
  {
   "cell_type": "code",
   "source": "class ISICDataset(Dataset):\n    \n    def __init__(self, df, transform=None, augmentation_transform=None):\n        self.df = df\n        self.transform = transform\n        self.augmentation_transform = augmentation_transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.df.loc[idx, \"img_path\"]).convert(\"RGB\")\n        img = v2.Resize(IMG_SIZE)(img)\n        img = v2.ToDtype(torch.float32, scale=True)(img)\n        label = self.df.loc[idx, \"target\"]\n        if self.augmentation_transform:    \n            img = self.augmentation_transform()(img) if random.random() > 0.2 else img\n        img = self.transform(img)\n        # if random.random() > 0.98:\n        #     plt.imshow(img.permute(1, 2, 0))\n        #     plt.show()\n        return img, label\n\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.680249Z",
     "iopub.execute_input": "2024-08-26T20:26:37.680589Z",
     "iopub.status.idle": "2024-08-26T20:26:37.693447Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.680557Z",
     "shell.execute_reply": "2024-08-26T20:26:37.692619Z"
    },
    "trusted": true
   },
   "id": "6c78f5c1786124dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "class BalancedBatchSampler(Sampler):\n\n    def __init__(self, class_0_df, class_1_df, batch_size, class_1_amount_per_batch=10):\n        self.class_0_df = class_0_df\n        self.class_1_df = class_1_df\n\n        self.batch_size = batch_size\n        self.class_1_amount_per_batch = class_1_amount_per_batch\n        self.num_batches = (len(self.class_0_df) + len(self.class_1_df)) // batch_size\n\n    def __iter__(self):\n        class_0_iter = iter(self.class_0_df.index)\n        class_1_iter = iter(self.class_1_df.index)\n        \n        for _ in range(self.num_batches):\n            batch = []\n            try:\n                for _ in range(self.class_1_amount_per_batch):\n                    batch.append(next(class_1_iter))\n            except:\n                class_1_iter = iter(self.class_1_df.index)\n                batch = []\n                for _ in range(self.class_1_amount_per_batch):\n                    batch.append(next(class_1_iter))\n            try:\n                for _ in range(self.batch_size - self.class_1_amount_per_batch):\n                    batch.append((next(class_0_iter)))\n            except:\n                class_0_iter = iter(self.class_0_df.index)\n                for _ in range(self.batch_size - self.class_1_amount_per_batch):\n                    batch.append(next(class_0_iter))\n            random.shuffle(batch)\n            for idx in batch:\n                yield idx\n\n    def __len__(self):\n        return self.num_batches\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.695760Z",
     "iopub.execute_input": "2024-08-26T20:26:37.696051Z",
     "iopub.status.idle": "2024-08-26T20:26:37.708764Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.696020Z",
     "shell.execute_reply": "2024-08-26T20:26:37.708002Z"
    },
    "trusted": true
   },
   "id": "9768ee9b38740db3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# model",
   "metadata": {},
   "id": "529705da4dca85bd"
  },
  {
   "cell_type": "code",
   "source": [
    "def load_model(model_name=\"resnet50\", num_classes=2):\n",
    "\n",
    "    if model_name == \"mobilenet_v3_small\":\n",
    "        model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "    \n",
    "    elif model_name == \"efficientnet_v2_m\":\n",
    "        model = models.efficientnet_v2_m(weights=models.EfficientNet_V2_M_Weights.DEFAULT)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    \n",
    "    elif model_name == \"efficientnet_b0\":\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    \n",
    "    elif model_name == \"vgg16\":\n",
    "        model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    \n",
    "    elif model_name == \"resnet50\":\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "    elif model_name == \"resnet18\":\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "    elif model_name == \"vit_b_16\":\n",
    "        model = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n",
    "        in_features = model.heads.head.in_features\n",
    "        model.heads.head = nn.Linear(in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} is not supported yet\")\n",
    "        \n",
    "#     print(model)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    return model\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.709711Z",
     "iopub.execute_input": "2024-08-26T20:26:37.710029Z",
     "iopub.status.idle": "2024-08-26T20:26:37.722943Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.709996Z",
     "shell.execute_reply": "2024-08-26T20:26:37.722212Z"
    },
    "trusted": true
   },
   "id": "ccba580879c42adc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "k_models = []\n",
    "for model_name in MODELS_NAMES:\n",
    "    k_models.append(load_model(model_name=model_name, num_classes=NUM_CLASSES))\n",
    "\n",
    "optimizer = AdamW([param for model in k_models for param in model.parameters()], lr=LR)\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=ISIC_df['target'])\n",
    "weights = torch.tensor(class_weights, dtype=torch.float32)  # increase cause model will pay more in mistakes\n",
    "criterion =  nn.CrossEntropyLoss(weight=weights) if NUM_CLASSES == 2 else nn.BCELoss()\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.723949Z",
     "iopub.execute_input": "2024-08-26T20:26:37.724254Z",
     "iopub.status.idle": "2024-08-26T20:26:37.824412Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.724223Z",
     "shell.execute_reply": "2024-08-26T20:26:37.823643Z"
    },
    "trusted": true
   },
   "id": "5fe80c1073873266",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# training func",
   "metadata": {},
   "id": "192c1018356be02a"
  },
  {
   "cell_type": "code",
   "source": [
    "def train(dataloader, k_models, optimizer, criterion):\n",
    "    total_loss = 0\n",
    "    sum_batches = 0\n",
    "    for batch, (imgs, labels) in enumerate(dataloader):\n",
    "        sum_batches += 1\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        if NUM_CLASSES == 2:\n",
    "            pred_labels = torch.zeros(imgs.size(0), 2, dtype=torch.float32, device=device)\n",
    "            for model in k_models:\n",
    "                model.train()\n",
    "                pred_labels = pred_labels + model(imgs)\n",
    "            pred_labels = pred_labels / len(k_models)\n",
    "        else:\n",
    "            raise Exception(f\"define NUM_CLASSES\")\n",
    "        \n",
    "        loss = criterion(pred_labels, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # try:\n",
    "        #     scheduler.step()\n",
    "        # except:\n",
    "        #     print('cosine warmup ERROR')\n",
    "        #     \n",
    "        total_loss += loss.item()\n",
    "        lr_values.append(optimizer.param_groups[0]['lr'])\n",
    "        if batch % 10 == 0:\n",
    "            print(f\"{batch + 1} from {len(dataloader) * BATCH_SIZE}, lr: {optimizer.param_groups[0]['lr']}\")\n",
    "    return total_loss / sum_batches\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.825957Z",
     "iopub.execute_input": "2024-08-26T20:26:37.826268Z",
     "iopub.status.idle": "2024-08-26T20:26:37.834469Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.826234Z",
     "shell.execute_reply": "2024-08-26T20:26:37.833470Z"
    },
    "trusted": true
   },
   "id": "2d958b2eb5749d20",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def test(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    pred_arr = [0, 1] # initialize for cases where only class_0 or only class_1 \n",
    "    labels_arr = [1, 0]\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (imgs, labels) in enumerate(dataloader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            if NUM_CLASSES == 1:\n",
    "                labels = labels.unsqueeze(1).float()\n",
    "    \n",
    "                pred_labels = model(imgs)\n",
    "                pred_labels = torch.sigmoid(pred_labels)\n",
    "                loss = criterion(pred_labels, labels)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                pred_arr = np.concatenate((pred_arr, pred_labels.cpu().flatten().detach().numpy()), axis=None)\n",
    "                labels_arr = np.concatenate((labels_arr, labels.cpu().flatten().detach().numpy()), axis=None)\n",
    "                \n",
    "            elif NUM_CLASSES == 2:\n",
    "                pred_labels = torch.zeros(imgs.size(0), 2, dtype=torch.float32, device=device)\n",
    "                for model in k_models:\n",
    "                    model.eval()\n",
    "                    pred_labels = pred_labels + model(imgs)\n",
    "                pred_labels = pred_labels / len(k_models)\n",
    "                \n",
    "                loss = criterion(pred_labels, labels)\n",
    "                total_loss += loss.item()\n",
    "                probabilities = nn.functional.softmax(pred_labels, dim=1)\n",
    "                \n",
    "                pred_arr = pred_arr + probabilities[:, 1].cpu().flatten().detach().numpy().tolist()\n",
    "                labels_arr = labels_arr + labels.detach().flatten().cpu().numpy().tolist()\n",
    "                \n",
    "            else:\n",
    "                raise Exception(f\"define NUM_CLASSES\")\n",
    "            \n",
    "            if batch % 5 == 0:\n",
    "                print(f\"{batch + 1} from {len(dataloader)}, loss: {loss}, auc: {roc_auc_80(pred_arr, labels_arr)}\")\n",
    "    return total_loss / len(dataloader), roc_auc_80(pred_arr, labels_arr)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.835599Z",
     "iopub.execute_input": "2024-08-26T20:26:37.835943Z",
     "iopub.status.idle": "2024-08-26T20:26:37.849039Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.835911Z",
     "shell.execute_reply": "2024-08-26T20:26:37.848200Z"
    },
    "trusted": true
   },
   "id": "507e17d1e98eab3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## running (and initialize the data) ",
   "metadata": {},
   "id": "ce719341aed6f0c9"
  },
  {
   "cell_type": "code",
   "source": [
    "k_models = []\n",
    "lr_values = []\n",
    "\n",
    "final_arr = []\n",
    "for fold, (train_df, val_df) in enumerate(k_fold):\n",
    "    \n",
    "    train_df = ISIC_df.loc[train_df, ['img_path', 'target']]\n",
    "    val_df = ISIC_df.loc[val_df, ['img_path', 'target']]\n",
    "    \n",
    "    train_loss_arr = []\n",
    "    test_loss_arr = []\n",
    "    test_auc_arr = []\n",
    "    gap = \"------------------------------\"\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_dataloader, val_dataloader = get_dataloader_with_undersampling(train_df, val_df, 2000, 2000)\n",
    "    \n",
    "        print(f\"{gap}\\nepoch: {epoch + 1}\\n{gap}\")\n",
    "    \n",
    "        print(\"train:\")\n",
    "        train_loss_arr.append(train(train_dataloader, k_models[:fold] + k_models[fold + 1:], optimizer, criterion))\n",
    "        print(\"test:\")\n",
    "        loss, auc_ = test(val_dataloader, k_models[:fold] + k_models[fold + 1:], criterion)\n",
    "    \n",
    "        test_loss_arr.append(loss)\n",
    "        test_auc_arr.append(auc_)\n",
    "        \n",
    "        print(f\"train_loss_arr: {train_loss_arr[-1]} ; test_loss_arr: {test_loss_arr[-1]} ; test_auc_arr: {test_auc_arr[-1]} ;\")\n",
    "        if test_auc_arr[-1] > 0.16:\n",
    "            for i in range(len(k_models)):\n",
    "                torch.save(k_models[i].state_dict(), f\"model_{epoch + 1}_{str(test_loss_arr[-1])[2:5]}_{MODELS_NAMES[i]}_{NAMES_SAVED_MODELS}.pth\")\n",
    "            print(f\"Saved PyTorch Models State to models_{epoch + 1}.pth\")\n",
    "        \n",
    "    final_arr.append(pd.DataFrame({\"train_loss_arr\":train_loss_arr, \"test_loss_arr\":test_loss_arr, \"test_auc_arr\":test_auc_arr}))\n",
    "    print(\"done!\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T20:26:37.850174Z",
     "iopub.execute_input": "2024-08-26T20:26:37.850628Z",
     "iopub.status.idle": "2024-08-26T20:26:43.930149Z",
     "shell.execute_reply.started": "2024-08-26T20:26:37.850585Z",
     "shell.execute_reply": "2024-08-26T20:26:43.929129Z"
    },
    "trusted": true
   },
   "id": "6e2a7f7a34f6c5fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# get prediction with kfolds for adding into tabular",
   "id": "b987089207c059be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6bdb594ca7dfa55b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for fold, (train_df, val_df) in enumerate(k_fold):\n",
    "    \n",
    "    train_df = ISIC_df.loc[train_df, ['img_path', 'target']]\n",
    "    val_df = ISIC_df.loc[val_df, ['img_path', 'target']]\n",
    "    \n",
    "    model, optimizer, criterion = k_models[fold]\n",
    "    \n",
    "    test_loss_arr = []\n",
    "    test_auc_arr = []\n",
    "    gap = \"------------------------------\"\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_dataloader, val_dataloader = get_dataloader_with_undersampling(train_df, val_df, 2000, 2000)\n",
    "    \n",
    "        print(f\"{gap}\\nepoch: {epoch + 1}\\n{gap}\")\n",
    "        print(\"test:\")\n",
    "        loss, auc_ = test(val_dataloader, model, criterion)\n",
    "    \n",
    "        test_loss_arr.append(loss)\n",
    "        test_auc_arr.append(auc_)\n",
    "        # torch.save(model.state_dict(), f\"model_{epoch + 1}.pth\")\n",
    "        # print(f\"Saved PyTorch Model State to model_{epoch + 1}.pth\")\n",
    "        print(\n",
    "            f\"test_loss_arr: {test_loss_arr[-1]} ; test_auc_arr: {test_auc_arr[-1]} ;\")\n",
    "        \n",
    "    k_models[fold] = (model, optimizer, criterion)\n",
    "    pd.DataFrame({\"test_loss_arr\":test_loss_arr, \"test_auc_arr\":test_auc_arr})\n",
    "    print(\"done!\")"
   ],
   "id": "e7e4f9e7a5259f7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# need a small corrections. its temporarily",
   "id": "3e04490b5c1884f6"
  }
 ]
}
